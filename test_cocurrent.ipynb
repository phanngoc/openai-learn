{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=apiKey)\n",
    "print(apiKey)\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.vdsc.com.vn/vi/Com_Document/VNM/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f            Công ty Cổ phần Sữa Việt Nam và các công ty con        NỘI DUNG         THÔNG TIN VỀ CÔNG TY          BÁO CÁO CỦA BAN ĐIỀU HÀNH          BÁO CÁO TÌNH HÌNH TÀI CHÍNH HỢP NHẤT          BÁO CÁO KẾT QUẢ HOẠT ĐỘNG KINH DOANH HỢP NHẤT          BÁO CÁO LƯU CHUYỂN TIỀN TỆ HỢP NHẤT          THUYẾT MINH BÁO CÁO TÀI CHÍNH HỢP NHẤT     TRANG     2     3          4 - 6     7 - 8     9 - 11     12 - 61    1     \f            Công ty Cổ phần Sữa Việt Nam và các công ty con   Thông tin về Công ty   \n"
     ]
    }
   ],
   "source": [
    "# load the pdf file\n",
    "path = './data/1517456934-51f84d5d6cb5ceae2465a7da470fc533ac4830e4776cc0fd3aa76c0fe7537c8e.pdf'\n",
    "import textract\n",
    "import tiktoken\n",
    "\n",
    "# Extract the raw text from each PDF using textract\n",
    "text = textract.process(path, method='pdfminer').decode('utf-8')\n",
    "clean_text = text.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')\n",
    "print(clean_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "def extract_chunk(content, template_prompt, response_format = \"text\", gpt_model = GPT_MODEL):\n",
    "    \"\"\"This function applies a prompt to some input content. In this case it returns a summarized chunk of text\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{template_prompt}\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, messages=messages, temperature=0.7,\n",
    "        response_format={ \"type\": response_format }\n",
    "    )\n",
    "\n",
    "    return response.choices[0]\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def embedding_request(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input = [text], model=EMBEDDING_MODEL).data[0].embedding\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_61481/3439893579.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Góc nhìn chuyên gia: Khả năng thị trường còn đ...   \n",
      "1  Vì sao vợ chồng tổng giám đốc CII muốn bán sạc...   \n",
      "2  Chứng khoán giảm 4 tuần liên tục, nhà đầu tư l...   \n",
      "3  Khải Hoàn Land (KHG) muốn chào bán riêng lẻ 18...   \n",
      "4  Đất Xanh Services (DXS) chốt ngày phát hành 12...   \n",
      "\n",
      "                                             content                date  \n",
      "0  \\n\\n\\n\\n\\nTIN MỚI\\n\\n\\n\\n\\n    Thị trường chứn... 2023-08-10 12:58:00  \n",
      "1  \\n\\n\\n\\n\\r\\n                    CII: \\n\\n\\n\\n\\... 2023-09-10 09:35:00  \n",
      "2  \\n\\n\\n\\n\\nTIN MỚI\\n\\n\\n\\n\\n\\nKhông phục hồi nh... 2023-07-10 19:01:00  \n",
      "3  \\n\\n\\n\\n\\r\\n                    KHG: \\n\\n\\n\\n\\... 2023-06-10 10:20:00  \n",
      "4  \\n\\n\\n\\n\\r\\n                    DXS: \\n\\n\\n\\n\\... 2023-05-10 01:00:00  \n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_news_date(date_start, date_end = None):\n",
    "\n",
    "    # check exist date_end or get current date\n",
    "    if date_end is None:\n",
    "        date_end = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Establish a connection to the MySQL database\n",
    "    connection = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=13306,\n",
    "        user='root',\n",
    "        password='root',\n",
    "        database='pyml'\n",
    "    )\n",
    "\n",
    "    # Read the table data using pandas\n",
    "    query = f\"\"\"\n",
    "        SELECT title, content, date FROM crawl_data\n",
    "        where DATE(date) >= '{date_start}' and DATE(date) <= '{date_end}'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, connection)\n",
    "    return df\n",
    "\n",
    "df_news = get_news_date('2023-05-01', '2023-12-30')\n",
    "\n",
    "print(df_news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Góc nhìn chuyên gia: Khả năng thị trường còn điều chỉnh, tận dụng cơ hội gom một số nhóm cổ phiếu đón sóng quý 4\n"
     ]
    }
   ],
   "source": [
    "title = df_news['title'][0]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_max = embedding_request(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(emd_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Góc nhìn chuyên gia: Khả năng thị trường còn điều chỉnh, tận dụng cơ hội gom một số nhóm cổ phiếu đó\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "df_check = df_news.head(2)\n",
    "# Get the titles and contents from df_news\n",
    "titles = df_check['title']\n",
    "contents = df_check['content']\n",
    "\n",
    "print(type(titles + contents))\n",
    "# Concatenate the titles and contents into a single variable\n",
    "concatenated_text = reduce(lambda x, y: x + y, titles)\n",
    "\n",
    "print(concatenated_text[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "chunks = create_chunks(concatenated_text, 1000, tokenizer)\n",
    "text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "template_prompt = \"\"\"Với thông tin này hãy phân tích khuynh hướng chứng khoáng sẽ tăng hay giảm:\n",
    "    Use format json:\n",
    "    {\n",
    "        Các yếu tố rất tích cực: <nội dung>\n",
    "        Các yếu tố hơi tích cực: <nội dung>\n",
    "        Các yếu tố trung lập: <nội dung>\n",
    "        Các yếu tố hơi tiêu cực: <nội dung>\n",
    "        Các yếu tố rất tiêu cực: <nội dung>\n",
    "    } \\n\\n \"\"\"\n",
    "\n",
    "\n",
    "results = []\n",
    "for chunk in text_chunks:\n",
    "    responseChoice = extract_chunk(chunk, template_prompt, 'json_object', 'gpt-3.5-turbo-1106')\n",
    "    results.append({'chunk': chunk, 'summarize': responseChoice.message.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chunk': 'Góc nhìn chuyên gia: Khả năng thị trường còn điều chỉnh, tận dụng cơ hội gom một số nhóm cổ phiếu đón sóng quý 4Vì sao vợ chồng tổng giám đốc CII muốn bán sạch cổ phiếu?', 'summarize': '{\\n    \"Các yếu tố rất tích cực\": \"Khả năng thị trường còn điều chỉnh, tạo cơ hội cho việc gom một số nhóm cổ phiếu đón sóng quý 4.\",\\n    \"Các yếu tố hơi tích cực\": \"Khả năng tận dụng cơ hội từ việc bán sạch cổ phiếu của vợ chồng tổng giám đốc CII để định vị lại danh mục đầu tư.\",\\n    \"Các yếu tố trung lập\": \"Thông tin về việc vợ chồng tổng giám đốc CII muốn bán sạch cổ phiếu cần được xem xét kỹ lưỡng trước khi đưa ra kết luận.\",\\n    \"Các yếu tố hơi tiêu cực\": \"Việc vợ chồng tổng giám đốc CII muốn bán sạch cổ phiếu có thể tạo ra áp lực bán ra trên thị trường cổ phiếu.\",\\n    \"Các yếu tố rất tiêu cực\": \"Không có thông tin rõ ràng về lý do vợ chồng tổng giám đốc CII muốn bán sạch cổ phiếu, có thể tạo ra sự lo ngại và không tin tưởng từ phía nhà đầu tư.\"\\n}'}]\n",
      "                                               chunk  \\\n",
      "0  Góc nhìn chuyên gia: Khả năng thị trường còn đ...   \n",
      "\n",
      "                                           summarize  \n",
      "0  {\\n    \"Các yếu tố rất tích cực\": \"Khả năng th...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/37kt02914kx36yzcbbqfyck00000gn/T/ipykernel_61481/624030665.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_cached = df_cached.append(results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "df_cached = pd.DataFrame(columns=['chunk', 'summarize'])\n",
    "df_cached = df_cached.append(results, ignore_index=True)\n",
    "\n",
    "print(df_cached.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               chunk  \\\n",
      "0  Góc nhìn chuyên gia: Khả năng thị trường còn đ...   \n",
      "\n",
      "                                           summarize  \\\n",
      "0  {\\n    \"Các yếu tố rất tích cực\": \"Khả năng th...   \n",
      "\n",
      "                                      summarize_json  \n",
      "0  {     \"Các yếu tố rất tích cực\": \"Khả năng thị...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_json(x):\n",
    "    x = x.replace('\\n', ' ')\n",
    "    parsed_json = json.loads(x)\n",
    "    return parsed_json\n",
    "\n",
    "df_cached['summarize_json'] = df_cached['summarize'].apply(lambda x: x.replace('\\n', ' '))\n",
    "print(df_cached.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100,\n",
    ") -> list[str]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = embedding_request(query)\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"filepath\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
